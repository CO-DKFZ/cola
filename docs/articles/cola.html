<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title> • cola</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/all.min.css" integrity="sha256-nAmazAk6vS34Xqo0BSrTb+abbtFlgsFK7NKSi6o7Y78=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.7.1/css/v4-shims.min.css" integrity="sha256-6qHlizsOWFskGlwVOKuns+D1nB6ssZrHQrNj1wGplHc=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" integrity="sha256-FiZwavyI2V6+EXO1U+xzLG3IKldpiTFf3153ea9zikQ=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/headroom.min.js" integrity="sha256-DJFC1kqIhelURkuza0AvYal5RxMtpzLjFhsnVIeuk+U=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.9.4/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">cola</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">1.1.2</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/cola.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/a_quick_start.html">UNKNOWN TITLE</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/jokergoo/cola">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1></h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/jokergoo/cola/blob/master/vignettes/cola.Rmd"><code>vignettes/cola.Rmd</code></a></small>
      <div class="hidden name"><code>cola.Rmd</code></div>

    </div>

    
    
<!--
%\VignetteEngine{knitr}
%\VignetteIndexEntry{2. A Framework for Consensus and Hierarchical Partitioning}
-->

<div id="cola-a-general-framework-for-consensus-and-hierarchical-partitioning" class="section level1">
<h1 class="hasAnchor">
<a href="#cola-a-general-framework-for-consensus-and-hierarchical-partitioning" class="anchor"></a>cola: A General Framework for Consensus and Hierarchical Partitioning</h1>
<p><strong>Author</strong>: Zuguang Gu ( <a href="mailto:z.gu@dkfz.de">z.gu@dkfz.de</a> )</p>
<p><strong>Date</strong>: 2019-10-23</p>
<p><strong>Package version</strong>: 1.1.2</p>
<hr>
<div id="introduction" class="section level2">
<h2 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h2>
<p>Subgroup classification is a basic task in high-throughput genomic data analysis, especially for gene expression and DNA methylation data analysis. Mostly, unsupervised clustering methods are applied to predict new subgroups or test the consistency with known annotations.</p>
<p>To test the stability of subgroup classifications, <a href="https://en.wikipedia.org/wiki/Consensus_clustering">consensus clustering</a> or consensus partitioning is always performed. It clusters repeatedly with a randomly sampled subset of data and summarizes the robustness of the clustering, finally it gives a consensus classification of all samples.</p>
<p>Here we present the <strong>cola</strong> package which provides a general framework for consensus partitioning. It has following advantages:</p>
<ol style="list-style-type: decimal">
<li>It modularizes the consensus partitioning processes that various methods can be easily integrated in different steps of the analysis.</li>
<li>It provides rich visualizations for interpreting the results.</li>
<li>It allows running multiple methods at the same time and provides functionalities to compare results in a straightforward way.</li>
<li>It provides a new method to extract features which are more efficient to separate subgroups.</li>
<li>It allows doing partitioning in a hierarchical way to detect subgroups with relatively smaller difference.</li>
<li>It generates detailed HTML reports for the complete analysis.</li>
</ol>
<p>Following flowchart lists the general steps of consensus partitioning implemented by <strong>cola</strong>:</p>
<p><img src="consensus_partition_workflow.png" width="600"></p>
<p>The steps are:</p>
<ol style="list-style-type: decimal">
<li>Clean the input matrix. The processings are: adjusting outliers, imputing missing values and removing rows with very small variance. This step is optional.</li>
<li>Extract subset of rows with highest scores. Here “scores” are calculated by a certain method. For gene expression analysis or methylation data analysis, <span class="math">\(n\)</span> rows with highest variance are used in most studies, where the “method”, or let’s call it <strong>“the top-value method”</strong> is the variance (by <code><a href="https://rdrr.io/r/stats/cor.html">var()</a></code> or <code><a href="https://rdrr.io/r/stats/sd.html">sd()</a></code>). Note the choice of “the top-value method” can be general. It can be e.g. MAD (median absolute deviation) or any user-defined method.</li>
<li>Scale the rows in the sub-matrix (e.g. gene expression) or not (e.g. methylation data). This step is optional.</li>
<li>Randomly sample a subset of rows from the sub-matrix with probability <span class="math">\(p\)</span> and perform partitioning on the columns of the matrix by a certain partition method, with trying different numbers of subgroups.</li>
<li>Repeat step 4 several times and collect all the partitions.</li>
<li>Perform consensus partitioning analysis and determine the best number of subgroups which gives the most stable subgrouping.</li>
<li>Apply statistical tests to find rows that show significant difference between the predicted subgroups. E.g. to extract subgroup specific genes.</li>
<li>If rows in the matrix can be associated to genes, downstream analysis such as function enrichment analysis can be performed.</li>
</ol>
<p>All the steps will be explained in detail in following sections.</p>
<p>First of all, we load the <strong>cola</strong> package.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(cola)</code></pre>
</div>
<div id="the-input-matrix" class="section level2">
<h2 class="hasAnchor">
<a href="#the-input-matrix" class="anchor"></a>The input matrix</h2>
<p>In most of the analysis tasks, the input matrix contains values of gene expression or DNA methylation (from methylation array or whole genome bisulfite sequencing). If it is an expression matrix, rows correspond to genes, and if it is a methylation matrix, rows correspond to CpG sites. For both types of matrices, columns should always correspond to samples where subgroups are detected. More general, the input matrix can be any type of measurements as long as they represent in a form of matrix, e.g. a matrix where rows are genomic regions and values are the histone modification intensities in the regions, measured from a ChIP-Seq experiment.</p>
<p>In following part of this vignette, we always call the matrix columns as “samples”.</p>
<p>Before doing consensus partition, a simple but important step is to clean the input matrix:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># code is only for demonstration</span>
mat =<span class="st"> </span><span class="kw"><a href="../reference/adjust_matrix.html">adjust_matrix</a></span>(mat)</code></pre>
<p><code><a href="../reference/adjust_matrix.html">adjust_matrix()</a></code> does following preprocessings:</p>
<ol style="list-style-type: decimal">
<li>Rows where more than 25% of the samples having <code>NA</code> values are removed;</li>
<li>Use <code><a href="https://rdrr.io/pkg/impute/man/impute.knn.html">impute::impute.knn()</a></code> to impute missing data if there is any;</li>
<li>For each row in the matrix, it uses <code><a href="../reference/adjust_outlier.html">adjust_outlier()</a></code> (also provided by <strong>cola</strong> package) to adjust outliers. Values larger than the 95^th percentile or less than the 5^th percentile are replaced by corresponding percentiles.</li>
<li>Rows with zero variance are removed.</li>
<li>Rows with variance less than 5^th percentile of all row variance (after removing rows with zero variance) are removed.</li>
</ol>
<p>Some of the above steps are optional. For example, methylation matrix does not need to be adjusted for outliers because all the methylation values are already in a fixed data scale (0 ~ 1).</p>
</div>
<div id="basic-usage" class="section level2">
<h2 class="hasAnchor">
<a href="#basic-usage" class="anchor"></a>Basic usage</h2>
<p><code><a href="../reference/consensus_partition.html">consensus_partition()</a></code> performs consensus partitioning for a single top-value method and a single partition method. The major arguments for <code><a href="../reference/consensus_partition.html">consensus_partition()</a></code> are:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># code is only for demonstration</span>
res =<span class="st"> </span><span class="kw"><a href="../reference/consensus_partition.html">consensus_partition</a></span>(mat,
    <span class="dt">top_value_method =</span> <span class="st">"MAD"</span>,
    <span class="dt">top_n =</span> <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">1000</span>, <span class="dv">2000</span>, <span class="dv">3000</span>, <span class="dv">4000</span>, <span class="dv">5000</span>),
    <span class="dt">partition_method =</span> <span class="st">"kmeans"</span>,
    <span class="dt">max_k =</span> <span class="dv">6</span>,
    <span class="dt">p_sampling =</span> <span class="fl">0.8</span>,
    <span class="dt">partition_repeat =</span> <span class="dv">50</span>,
    <span class="dt">anno =</span> <span class="ot">NULL</span>)</code></pre>
<ul>
<li>
<code>mat</code>: a data matrix where subgroups are found by columns.</li>
<li>
<code>top_value_method</code>: name of the method to assign scores to matrix rows. Later these scores are used to order and extract rows with top values.</li>
<li>
<code>top_n</code>: number of rows with top values used for partitioning. Normally we set <code>top_n</code> as a vector of different numbers.</li>
<li>
<code>partition_method</code>: name of the method for partitioning.</li>
<li>
<code>max_k</code>: maximal number of subgroups to try. It will try from 2 to <code>max_k</code>.</li>
<li>
<code>p_sampling</code>: fraction of the <code>top_n</code> rows to sample. The sub-matrix with <code>p_sample * top_n</code> rows is used for partitioning.</li>
<li>
<code>partition_repeats</code>: times of partitioning with randomly sampled subset of data to perform.</li>
<li>
<code>anno</code>: a vector or a data frame which contains known annotations of samples. If it is provided, it will drawn along side with the predicted subgroups in the plot generated by downstream functions and it can also be tested for the correspondance to predicted subgroups.</li>
</ul>
<p>Other arguments can be found in the on-line documentation of <code><a href="../reference/consensus_partition.html">consensus_partition()</a></code>.</p>
<p>To get a robust result from consensus partitioning, for a specific top-value method and a specific partition method, <code><a href="../reference/consensus_partition.html">consensus_partition()</a></code> tries different <code>top_n</code> and different number of subgroups. We found that different <code>top_n</code> might give different subgroups for some data sets, thus <code><a href="../reference/consensus_partition.html">consensus_partition()</a></code> pools results from different <code>top_n</code> and aims to give a general consensus subgrouping across different <code>top_n</code>. Later, we will introduce that the bias for <code>top_n</code> on subgrouping can be visualized by <code><a href="../reference/membership_heatmap-ConsensusPartition-method.html">membership_heatmap()</a></code> function.</p>
<p>In most cases, users might not be very sure which top-value method and which partition method are best for their dataset. The helper function <code><a href="../reference/run_all_consensus_partition_methods.html">run_all_consensus_partition_methods()</a></code> is a convenient way to try multiple top-value methods and multiple partition methods simultaneously to see which combination of methods gives the best prediction of subgroups.</p>
<p>In <code><a href="../reference/run_all_consensus_partition_methods.html">run_all_consensus_partition_methods()</a></code>, most of the arguments are the same as in <code><a href="../reference/consensus_partition.html">consensus_partition()</a></code>, except <code>top_value_method</code> and <code>partition_method</code> now accept a vector of method names and multiple cores can be set by <code>mc.cores</code> argument.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># code is only for demonstration</span>
rl =<span class="st"> </span><span class="kw"><a href="../reference/run_all_consensus_partition_methods.html">run_all_consensus_partition_methods</a></span>(mat, 
    <span class="dt">top_value_method =</span> <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"sd"</span>, <span class="st">"MAD"</span>, ...),
    <span class="dt">partition_method =</span> <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"hclust"</span>, <span class="st">"kmeans"</span>, ...),
    <span class="dt">mc.cores =</span> ...)
<span class="kw"><a href="../reference/cola_report-dispatch.html">cola_report</a></span>(rl, <span class="dt">output_dir =</span> ...)</code></pre>
<p>There are many functions in <strong>cola</strong> package that can be applied to <code>rl</code> to visualize and compare the results for all combinations of methods simultaneously.</p>
<p><code><a href="../reference/cola_report-dispatch.html">cola_report()</a></code> function can be applied on <code>rl</code> to generate a HTML report for the complete analysis, with all the plots and tables generated.</p>
</div>
<div id="top-value-methods" class="section level2">
<h2 class="hasAnchor">
<a href="#top-value-methods" class="anchor"></a>Top-value methods</h2>
<p>Top-value methods are used to assign scores to matrix rows, later the scores are ordered and only the top <span class="math">\(n\)</span> rows with the highest scores are used for consensus partitioning. The default top-value methods provided in the package are:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/all_top_value_methods.html">all_top_value_methods</a></span>()</code></pre>
<pre><code>## [1] "sd"  "cv"  "MAD" "ATC"</code></pre>
<p>These top methods are:</p>
<ul>
<li>
<code>sd</code>: Standard deviation.</li>
<li>
<code>cv</code>: <a href="https://en.wikipedia.org/wiki/Coefficient_of_variation">Coefficient of variance</a>, defined as <code>sd/(mean + s0)</code> where <code>s0</code> is a penalty term which is the 10^th percentile of all row means to avoid small values dividing small values giving large values.</li>
<li>
<code>MAD</code>: <a href="https://en.wikipedia.org/wiki/Median_absolute_deviation">Median absolute deviation</a>.</li>
<li>
<code>ATC</code>: A new method proposed in <strong>cola</strong> package and it will be explained later in this section.</li>
</ul>
<p>These methods can be used in consensus partitioning by providing the name to the <code>top_value_method</code> argument in <code><a href="../reference/run_all_consensus_partition_methods.html">run_all_consensus_partition_methods()</a></code> or <code><a href="../reference/consensus_partition.html">consensus_partition()</a></code>.</p>
<p>You can register a new top-value method by <code><a href="../reference/register_top_value_methods.html">register_top_value_methods()</a></code>. The value should be functions. For each function, it should only have one argument which is the matrix for analysis and it must return a vector with scores for rows. In following example, the “max” method uses the row maximum as the row score and we also add the “QCD” (<a href="https://en.wikipedia.org/wiki/Quartile_coefficient_of_dispersion">quartile coefficient of dispersion</a>) method as a second method here.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/register_top_value_methods.html">register_top_value_methods</a></span>(
    <span class="dt">max =</span> function(mat) matrixStats::<span class="kw">rowMaxs</span>(mat),
    <span class="dt">QCD =</span> function(mat) {
        qa =<span class="st"> </span>matrixStats::<span class="kw">rowQuantiles</span>(mat, <span class="dt">probs =</span> <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">0.25</span>, <span class="fl">0.75</span>))
        (qa[, <span class="dv">2</span>] -<span class="st"> </span>qa[, <span class="dv">1</span>])/(qa[, <span class="dv">2</span>] +<span class="st"> </span>qa[, <span class="dv">1</span>])
    })
<span class="kw"><a href="../reference/all_top_value_methods.html">all_top_value_methods</a></span>()</code></pre>
<pre><code>## [1] "sd"  "cv"  "MAD" "ATC" "max" "QCD"</code></pre>
<p>By default, the consensus partition functions <code><a href="../reference/run_all_consensus_partition_methods.html">run_all_consensus_partition_methods()</a></code> uses all registered top-value methods, but still you can explicitly specify a subset of top-value methods. To remove registered top-value methods, simply use <code><a href="../reference/remove_top_value_methods.html">remove_top_value_methods()</a></code> by providing a vector of names.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/remove_top_value_methods.html">remove_top_value_methods</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"max"</span>, <span class="st">"QCD"</span>))
<span class="kw"><a href="../reference/all_top_value_methods.html">all_top_value_methods</a></span>()</code></pre>
<pre><code>## [1] "sd"  "cv"  "MAD" "ATC"</code></pre>
<div id="the-atc-method" class="section level3">
<h3 class="hasAnchor">
<a href="#the-atc-method" class="anchor"></a>The ATC method</h3>
<p>Choosing the top rows in the matrix is important for the subgroup classification. In most cases, we extract the most variable rows which is defined by row variance. However, sometimes it won’t give you meaningful rows which are efficient for subgroup classification. When random noise in the data increases, e.g. for single cell RNASeq data, the most variable genes are too weak to detect any stable subgroups.</p>
<p>If we think reversely, assuming there exist stable subgroups in the data, there must be groups of rows showing similar pattern to support the subgrouping, in other words, rows in the same groups should have high correlations to each other. Thus, if we can get rows that more correlated to others, they are more strong to form a stable subgroup for the samples. According to this thought, we designed the ATC method.</p>
<p>For row <span class="math">\(i\)</span> in a matrix, <span class="math">\(X\)</span> is a vector of <strong>the absolute correlation</strong> to all other rows, the ATC (ability to correlate to others) for row <span class="math">\(i\)</span> is defined as:</p>
<p><span class="math">\[ATC_i = 1 - \int_0^1F(x)\]</span></p>
<p>where <span class="math">\(F(x)\)</span> is the empirical CDF (cumulative distribution function) of <span class="math">\(X\)</span>.</p>
<p>In following plot, the line is the CDF curve. ATC is the area above the CDF curve. It can be imagined that when row <span class="math">\(i\)</span> correlates with more other rows, the CDF curve shifts more to the right, thus with higher ATC scores.</p>
<p><img src="cola_files/figure-html/unnamed-chunk-9-1.png" width="480" style="display: block; margin: auto;"></p>
<p>There can be scenarios when large number of rows are correlated to each other only with very small correlation values. They will gain high ATC value due to the large number of rows (which corresponds to the left part of the read area in above plot that close to <span class="math">\(x = 0\)</span>). To decrease such effect, the ATC definition can be slightly modified to:</p>
<p><span class="math">\[ATC_i = (1 - \alpha) - \int_{\alpha}^1F(x^{\beta})\]</span></p>
<p>where now <span class="math">\(ATC_i\)</span> is the red area only on the right of <span class="math">\(x = \alpha\)</span>. The coefficient <span class="math">\(\beta\)</span> is the power added to the absolute correlations that it decreases more for the smaller correlations. By Default <span class="math">\(\alpha\)</span> is set to 0 and <span class="math">\(\beta\)</span> is set to 1.</p>
<p>Next we perform a simulation test to show the attributes of ATC method. A matrix with 160 rows, 100 columns with random values are generated as follows:</p>
<ol style="list-style-type: decimal">
<li>100 rows with mean of 0. The covariance matrix is set to 0 and 1 on the diagnal;</li>
<li>10 rows with mean of 0. The covariance matrix is set to 0.8 and 1 on the diagnal. This simulates high correlations but in a small group of rows;</li>
<li>50 rows wiht mean of 0. The covariance matrix is set to 0.5 and 1 on the diagnal. This simulates intemediate correlations but in a large group of rows.</li>
</ol>
<p>The top left figure in following is the heatmap for the random matrix, split by the three groups of rows. In the top right figure, they are ECDF curves of the correlation when calculating ATC scores. The bottom left figure is the ATC scores for all 160 rows and the bottom right figure is the standard deviation for the 160 rows.</p>
<p><img src="cola_files/figure-html/unnamed-chunk-10-1.png" width="768" style="display: block; margin: auto;"></p>
<p>All the 160 rows have similar variance of 1 that they cannot be distinguished very well by using variance (bottom right figure). As a contrast, the rows with non-zero covariance have higher ATC values (the red and green points), even higher when the number of correlated rows increases (the green points, although the correlation value itself is intermediate, bottom left figure). This shows ATC method can assign higher values for rows which correlate to more other rows.</p>
<p>ATC scores are calculated by <code><a href="../reference/ATC.html">ATC()</a></code> function. By default it uses Pearson correlation. Users can register ATC method with other correlation methods by, e.g.:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># code is only for demonstration</span>
<span class="kw"><a href="../reference/register_top_value_methods.html">register_top_value_methods</a></span>(
    <span class="dt">ATC_spearman =</span> function(m) <span class="kw"><a href="../reference/ATC.html">ATC</a></span>(m, <span class="dt">method =</span> <span class="st">"spearman"</span>),
    <span class="dt">ATC_bicor =</span> function(m) <span class="kw"><a href="../reference/ATC.html">ATC</a></span>(m, <span class="dt">cor_fun =</span> WGCNA::bicor)
)</code></pre>
</div>
</div>
<div id="partition-methods" class="section level2">
<h2 class="hasAnchor">
<a href="#partition-methods" class="anchor"></a>Partition methods</h2>
<p>Partition methods are used to separate samples into <span class="math">\(k\)</span> subgroups where <span class="math">\(k\)</span> is a known parameter for the partition. The default partition methods are:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/all_partition_methods.html">all_partition_methods</a></span>()</code></pre>
<pre><code>## [1] "hclust"  "kmeans"  "skmeans" "pam"     "mclust" 
## attr(,"scale_method")
## [1] "z-score" "z-score" "z-score" "z-score" "z-score"</code></pre>
<p>These partition methods are:</p>
<ul>
<li>
<code>hclust</code>: hierarchical clustering + cutree. The parameters for calling <code><a href="https://rdrr.io/r/stats/hclust.html">hclust()</a></code> and <code><a href="https://rdrr.io/r/stats/dist.html">dist()</a></code> are all defaults for the two functions, thus it is Euclidean distance with “complete” clustering method.</li>
<li>
<code>kmeans</code>: k-means clustering.</li>
<li>
<code>skmeans</code>: spherical k-means clustering, from <strong>skmeans</strong> package.</li>
<li>
<code>pam</code>: partitioning around medoids, from <strong>cluster</strong> package.</li>
<li>
<code>mclust</code>: model-based clustering, from <strong>mclust</strong> package. The clustering is based on the first three principle dimensions from the original matrix.</li>
</ul>
<p>Similarly, you can register a new partition method by <code><a href="../reference/register_partition_methods.html">register_partition_methods()</a></code>. The value should be functions with two arguments which are the input matrix and number of partitions. There can be a third argument for the function which is <code>...</code> used for passing more arguments from <code><a href="../reference/consensus_partition.html">consensus_partition()</a></code>. The function should only return a vector of subgroup/class labels or an object that can be imported by <code><a href="https://rdrr.io/pkg/clue/man/cl_membership.html">clue::cl_membership()</a></code>. <strong>Please note the partition is applied on columns of the matrix and the number of unique levels of subgroup levels which are predicted by the partition method should not exceed <span class="math">\(k\)</span>.</strong></p>
<p>Following example registers a partition method which randomly assign subgroup labels to samples:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/register_partition_methods.html">register_partition_methods</a></span>(
    <span class="dt">random =</span> function(mat, k) {
        <span class="kw"><a href="https://rdrr.io/r/base/sample.html">sample</a></span>(letters[<span class="dv">1</span>:k], <span class="kw"><a href="../reference/ncol-dispatch.html">ncol</a></span>(mat), <span class="dt">replace =</span> <span class="ot">TRUE</span>)
    }
)</code></pre>
<p>Here the subgroup labels can be in any types (numbers, characters). They only need to be different for different classes. These labels will be re-coded with numeric indices internally (i.e. 1, 2, 3, …).</p>
<p>To remove a partition method, use <code><a href="../reference/remove_partition_methods.html">remove_partition_methods()</a></code>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/remove_partition_methods.html">remove_partition_methods</a></span>(<span class="st">"random"</span>)</code></pre>
<p>The built-in <code>hclust</code> method only uses Euclidean distance with “complete” clustering method, It is easy to define another <code>hclust</code> method:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># code is only for demonstration</span>
<span class="kw"><a href="../reference/register_partition_methods.html">register_partition_methods</a></span>(
    <span class="dt">hclust_cor =</span> function(mat, k) <span class="kw"><a href="https://rdrr.io/r/stats/cutree.html">cutree</a></span>(<span class="kw"><a href="https://rdrr.io/r/stats/hclust.html">hclust</a></span>(<span class="kw"><a href="https://rdrr.io/r/stats/dist.html">as.dist</a></span>(<span class="dv">1</span> -<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span>(mat))), k)
)</code></pre>
<p>Following code registers SOM and NMF partition methods:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># code is only for demonstration</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(kohonen)
<span class="kw"><a href="../reference/register_partition_methods.html">register_partition_methods</a></span>(
    <span class="dt">SOM =</span> function(mat, k, ...) {
        kr =<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/Round.html">floor</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span>(<span class="kw"><a href="../reference/ncol-dispatch.html">ncol</a></span>(mat)))
        somfit =<span class="st"> </span><span class="kw"><a href="https://rdrr.io/pkg/kohonen/man/supersom.html">som</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/t.html">t</a></span>(mat), <span class="dt">grid =</span> <span class="kw"><a href="https://rdrr.io/pkg/kohonen/man/unit.distances.html">somgrid</a></span>(kr, kr, <span class="st">"hexagonal"</span>), ...)
        m =<span class="st"> </span>somfit$codes[[<span class="dv">1</span>]]
        m =<span class="st"> </span>m[<span class="kw"><a href="https://rdrr.io/r/base/seq.html">seq_len</a></span>(<span class="kw"><a href="../reference/nrow-dispatch.html">nrow</a></span>(m)) %in%<span class="st"> </span>somfit$unit.classif, ]
        cl =<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/stats/cutree.html">cutree</a></span>(<span class="kw"><a href="https://rdrr.io/r/stats/hclust.html">hclust</a></span>(<span class="kw"><a href="https://rdrr.io/r/stats/dist.html">dist</a></span>(m)), k)
        group =<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/numeric.html">numeric</a></span>(<span class="kw"><a href="../reference/ncol-dispatch.html">ncol</a></span>(mat))
        for(cl_unique in <span class="kw"><a href="https://rdrr.io/r/base/unique.html">unique</a></span>(cl)) {
            ind =<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/grep.html">gsub</a></span>(<span class="st">"V"</span>, <span class="st">""</span>, <span class="kw"><a href="https://rdrr.io/r/base/names.html">names</a></span>(cl)[<span class="kw"><a href="https://rdrr.io/r/base/which.html">which</a></span>(cl ==<span class="st"> </span>cl_unique)]))
            l =<span class="st"> </span>somfit$unit.classif %in%<span class="st"> </span>ind
            group[l] =<span class="st"> </span>cl_unique
        }
        group
    }
)
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(NMF)
<span class="kw"><a href="../reference/register_partition_methods.html">register_partition_methods</a></span>(
    <span class="dt">NMF =</span> function(mat, k, ...) {
        fit =<span class="st"> </span><span class="kw"><a href="https://rdrr.io/pkg/NMF/man/nmf.html">nmf</a></span>(mat, <span class="dt">rank =</span> k, ...)
        <span class="kw"><a href="https://rdrr.io/r/base/apply.html">apply</a></span>(fit@fit@H, <span class="dv">2</span>, which.max)
    }, <span class="dt">scale_method =</span> <span class="st">"max-min"</span>
)</code></pre>
<p>For these two methods, users can simply use <code><a href="../reference/register_SOM.html">register_SOM()</a></code> and <code><a href="../reference/register_NMF.html">register_NMF()</a></code> functions in <strong>cola</strong> package.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># code is only for demonstration</span>
<span class="kw"><a href="../reference/register_SOM.html">register_SOM</a></span>()
<span class="kw"><a href="../reference/register_NMF.html">register_NMF</a></span>()</code></pre>
<p>In the code above, there is an additional argument <code>scale_method</code> for <code>register_partition_method()</code>. <code>scale_method</code> controls how to scale the matrix rows before partitioning if scaling is turned on <code><a href="../reference/consensus_partition.html">consensus_partition()</a></code> or <code><a href="../reference/run_all_consensus_partition_methods.html">run_all_consensus_partition_methods()</a></code>. There are three possible values:</p>
<ul>
<li>
<code>z-score</code>: z-score transformation, which is <code>(x - mean(x))/sd(x)</code>.</li>
<li>
<code>max-min</code>: <code>(x - min(x))/(max(x) - min(x))</code>, this ensures all the scaled values are non-negative.</li>
<li>
<code>none</code>: no scaling is performed.</li>
</ul>
<div id="the-skmeans-method" class="section level3">
<h3 class="hasAnchor">
<a href="#the-skmeans-method" class="anchor"></a>The skmeans method</h3>
<p>The skmeans method (<a href="https://www.jstatsoft.org/article/view/v050i10">the spherical k-means clustering</a>) is powerful to detect subgroups where samples in a same subgroup show strong correlations. skmeans clustering uses cosine similarity and projects data points onto a unit hyper-sphere. As we have tested for many datasets, skmeans is very efficient to detect stable subgroups.</p>
<p><img src="skmeans.png" width="400"></p>
</div>
</div>
<div id="consensus-partitioning" class="section level2">
<h2 class="hasAnchor">
<a href="#consensus-partitioning" class="anchor"></a>Consensus partitioning</h2>
<p>For a given number of top rows <span class="math">\(n_i\)</span>, the corresponding matrix with top rows denoted as <span class="math">\(M_i\)</span>, a subset of rows with probability of <span class="math">\(p\)</span> are randomly sampled from <span class="math">\(M_i\)</span> and a certain partition method is applied on it, generating a partition <span class="math">\(P_a\)</span>. In most of cases, we have no prior knowledge of which <span class="math">\(n_i\)</span> gives better results, thus, <strong>cola</strong> allows to try multiple <span class="math">\(n_i\)</span> and pool partitions from all <span class="math">\(n_i\)</span> together to find a consensus subgrouping, which also lets rows more on the top of the ranked list give higher weight for determining the final subgroups. Let’s assume top rows are tried for <span class="math">\(n_1\)</span>, <span class="math">\(n_2\)</span>, …, <span class="math">\(n_m\)</span> and the randomly sampling is performed for <span class="math">\(N_s\)</span> times, then, for a given number of subgroups <span class="math">\(k\)</span> for trying, the total number of partitions is <span class="math">\(N_P = m*N_s\)</span>.</p>
<div id="consensus-matrix" class="section level3">
<h3 class="hasAnchor">
<a href="#consensus-matrix" class="anchor"></a>Consensus matrix</h3>
<p>The consensus matrix measures how consistently two samples are in a same subgroup and it can be used to visualize or analysis the stability of the subgrouping. The value <span class="math">\(c_{ij}\)</span> in the consensus matrix is the probability of sample <span class="math">\(i\)</span> and sample <span class="math">\(j\)</span> in a same subgroup in all <span class="math">\(N_P\)</span> partitions. It is calculated as:</p>
<p><span class="math">\[c_{ij} = \sum_a^{N_p}I(s_{ia}, s_{ja})/N_P\]</span></p>
<p>where <span class="math">\(s_{ia}\)</span> is the subgroup label for sample <span class="math">\(i\)</span> in partition <span class="math">\(a\)</span> and <span class="math">\(I()\)</span> is the indicator function there <span class="math">\(I(x = y) = 1\)</span> and <span class="math">\(I(x \neq y) = 0\)</span>.</p>
<p>Assuming there are stable subgroups in a dataset, which means, for any pair of samples <span class="math">\(i\)</span> and <span class="math">\(j\)</span> both in a same subgroup, <span class="math">\(c_{ij}\)</span> is close to 1, and for any pairs in different subgroups, <span class="math">\(c_{ij}\)</span> is close to 0, if the consensus matrix is visualized as a heatmap, samples in the same subgroup will be represented as a block in the diagonal of the heatmap.</p>
<p>Following two heatmaps visualize two consensus matrices. The left one shows less stability of subgrouping than the right one, while for the right one, there are three very obvious blocks in the diagnal that in each block, the corresponding samples are very likely to be in a same subgroup.</p>
<p>In following two heatmaps, the right one corresponds to a more stable subgrouping.</p>
<p><img src="cola_files/figure-html/unnamed-chunk-18-1.png" width="864" style="display: block; margin: auto;"></p>
</div>
<div id="consensus-subgroup-labels" class="section level3">
<h3 class="hasAnchor">
<a href="#consensus-subgroup-labels" class="anchor"></a>Consensus subgroup labels</h3>
<p>As long as we have a list of <span class="math">\(N_P\)</span> partitions for a given subgroup number <span class="math">\(k\)</span>, we need to find a consensus partition based on all <span class="math">\(N_P\)</span> partitions.Internally, <strong>cola</strong> package uses the <strong>clue</strong> package to construct the “partition ensemble” and predict the consensus subgroups. The “SE” method from <code><a href="https://rdrr.io/pkg/clue/man/cl_consensus.html">clue::cl_consensus()</a></code> function (please check the on-line documentation of this function) are used to calculate the consensus subgroup labels. The consensus subgroups are labels by integers (i.e. 1, 2, 3, …).</p>
</div>
<div id="adjust-subgroup-labels" class="section level3">
<h3 class="hasAnchor">
<a href="#adjust-subgroup-labels" class="anchor"></a>Adjust subgroup labels</h3>
<p>The subgroup labels are assigned with numeric indices, however, in each partition, the assignment of the labels can be random, e.g. one same subgroup can be assigned with 1 in one partition, while in the other partition, it can be 2, but they are all identical for the sense of subgrouping. E.g. following partitions are all identical:</p>
<pre><code>1 1 1 1 1 1 1 2 2 2 2 2 2
2 2 2 2 2 2 2 1 1 1 1 1 1
a a a a a a a b b b b b b</code></pre>
<p>The subgroups are identical if switching the subgroup labels. This subgroup label adjustment is called <a href="https://en.wikipedia.org/wiki/Assignment_problem">the linear sum assignment problem</a>, which is solved by the <code>solve_LSAP()</code> function in <strong>clue</strong> package. The aim is to find a mapping <span class="math">\(m()\)</span> between two sets of labels to maximize <span class="math">\(\sum_i I(s_{1i}, m(s_{2i}))\)</span> where <span class="math">\(s_1\)</span> is the first label set and <span class="math">\(s_2\)</span> is the second label set.</p>
<p>In following example, if the mapping is <code>1 -&gt; 2, 2 -&gt; 1</code>, the second partition in following</p>
<pre><code>1 1 1 1 1 1 1 2 2 2 2 2 # in partition 1
2 2 2 2 2 1 1 1 1 1 1 1 # in partition 2</code></pre>
<p>is adjusted to</p>
<pre><code>1 1 1 1 1 1 1 2 2 2 2 2
1 1 1 1 1 2 2 2 2 2 2 2 # switch 1 &lt;-&gt; 2</code></pre>
<p>For the subgroups predicted by <code><a href="https://rdrr.io/pkg/clue/man/cl_consensus.html">clue::cl_consensus()</a></code>, the labels are additionally adjusted by the mean distance in each subgroup (calculated from the scaled data matrix), which means, the subgroup with label 1 always has the smallest mean intra-group distance.</p>
<p><strong>This subgroup label adjustment is frequently used in cola to help the visualization as well as downstream analysis. E.g. for a specific combination of top-value method and partition method, the subgroup labels for different <code>k</code> are adjusted, and for the subgroups from different top-value methods and partition methods, the subgroup labels are also adjusted to make the label difference from different methods minimal.</strong></p>
</div>
<div id="membership-matrix" class="section level3">
<h3 class="hasAnchor">
<a href="#membership-matrix" class="anchor"></a>Membership matrix</h3>
<p>The <span class="math">\(N_P\)</span> partitions are stored as a membership matrix where rows are partitions (grouped by <code>top_n</code>) and the subgroup labels in each partition are adjusted according to the consensus partition. Following heatmap is a visualization of all partitions and correspondence to the consensus partition for <span class="math">\(k = 2\)</span>. The <code>p*</code> annotation on top of the heatmap is the probability of being in subgroup <span class="math">\(i\)</span> across all partitions.</p>
<p>In following plot, actually we can see the samples in the middle tend to belong to the green subgroup (group with label 1) for small <code>top_n</code> (e.g. <code>top_n = 1000</code>), while, when <code>top_n</code> increases, they go to the red subgroup (group label 2). Since the final subgroups are summarized from all <code>top_n</code>, the probabilities of the middle samples to be in the either subgroup are close, which can also be observed from the probability annotation (<code>p*</code> annotations). This might indicate these are the subset of samples which are in the intermediate state between group 1 and group 2.</p>
<p><img src="membership_heatmap.png"></p>
</div>
</div>
<div id="determine-the-best-number-of-subgroups" class="section level2">
<h2 class="hasAnchor">
<a href="#determine-the-best-number-of-subgroups" class="anchor"></a>Determine the best number of subgroups</h2>
<p>Consensus partitioning is applied with a specific number of subgroups (we term it as <span class="math">\(k\)</span>). Normally, a list of <span class="math">\(k\)</span> are tried to find the best <span class="math">\(k\)</span>. <strong>cola</strong> provides metrics to help to determine the best number of subgroups.</p>
<p>The <code><a href="../reference/get_stats-dispatch.html">get_stats()</a></code> function returns statistics for all metrics mentioned below and <code><a href="../reference/select_partition_number-ConsensusPartition-method.html">select_partition_number()</a></code> plots the statistics with the number of subgroups (an example is <a href="#toc_25">here</a>).</p>
<div id="silhouette-score" class="section level3">
<h3 class="hasAnchor">
<a href="#silhouette-score" class="anchor"></a>Silhouette score</h3>
<p><a href="https://en.wikipedia.org/wiki/Silhouette_%28clustering%29">The silhouette scores</a> measures how close one sample is in its own subgroup compared to the closest neighbouring subgroup. For sample <span class="math">\(i\)</span>, the mean distance to every subgroups are calculated, denoted as <span class="math">\(d_1\)</span>, <span class="math">\(d_2\)</span>, …, <span class="math">\(d_k\)</span> (<span class="math">\(d_k\)</span> is the mean Euclidean distance between sample <span class="math">\(i\)</span> and every sample in subgroup <span class="math">\(s\)</span>). The distance to the subgroup where sample <span class="math">\(i\)</span> stays is denoted as <span class="math">\(d_a\)</span> and the silhouette score is defined as:</p>
<p><span class="math">\[silhouette_i = 1 - d_a/d_b\]</span></p>
<p>where <span class="math">\(d_b\)</span> is the minimal distance excluding <span class="math">\(d_a\)</span>:</p>
<p><span class="math">\[d_b = min_{j \neq a}^k d_j\]</span></p>
<p>Following plot illustrates how silhouette score is calculated for sample <code>x_i</code>.</p>
<p><img src="cola_files/figure-html/unnamed-chunk-19-1.png" width="576" style="display: block; margin: auto;"></p>
<p>The mean silhouette score from all samples is used to choose the best <span class="math">\(k\)</span> where higher the mean silhouette score, better the <span class="math">\(k\)</span>.</p>
</div>
<div id="pac-score" class="section level3">
<h3 class="hasAnchor">
<a href="#pac-score" class="anchor"></a>PAC score</h3>
<p><a href="https://en.wikipedia.org/wiki/Consensus_clustering#Over-interpretation_potential_of_consensus_clustering">The PAC score</a> measures the proportion of the ambiguous subgrouping. If the subgrouping is stable, in <span class="math">\(N_P\)</span> partitions, sample <span class="math">\(i\)</span> and sample <span class="math">\(j\)</span>, in most of the cases, are either always in a same subgroup, or always in different subgroups, which results in that, in the consensus matrix, the values are, in most cases, close to 1 or 0. Then in the CDF of the consensus matrix, the curve will be very flattened between <span class="math">\(x_1\)</span> and <span class="math">\(x_2\)</span> where <span class="math">\(x_1\)</span> is very close to 0 and <span class="math">\(x_2\)</span> is very close to 1 because there are very few values between <span class="math">\(x_1\)</span> and <span class="math">\(x_2\)</span>. Thus, the proportion of sample pairs with consensus values in <span class="math">\((x_1, x_2)\)</span> is called <strong>the proportion of the ambiguous clustering</strong>, which can be calculated by <span class="math">\(F(x_2) - F(x_1)\)</span>.</p>
<p>In following plots, the red line in the left plot corresponds to the first consensus heatmap and the blue line corresponds to the second consensus heatmap that is more stable than the first one.It is quite obvious to see the second consensus heatmap has far less PAC value than the first one.</p>
<p><img src="cola_files/figure-html/unnamed-chunk-20-1.png" width="1344" style="display: block; margin: auto;"></p>
<p>In some cases, <span class="math">\(F(x_1)\)</span> or <span class="math">\(F(x_2)\)</span> changes a lot when <span class="math">\(x_1\)</span> has slight change around 0.1, or <span class="math">\(x_2\)</span> has slight change around 0.9. Thus, to make PAC not so sensitive to the selection of <span class="math">\(x_1\)</span> and <span class="math">\(x_2\)</span>, PAC value is calculated by removing 5% samples with lowest silhouette scores.</p>
<p>Smaller the PAC score, better the <span class="math">\(k\)</span>.</p>
</div>
<div id="concordance" class="section level3">
<h3 class="hasAnchor">
<a href="#concordance" class="anchor"></a>Concordance</h3>
<p>The concordance of partitions to the consensus partition is calculated as, for each partition <span class="math">\(P_a\)</span>, the probability that it fits the consensus partition:</p>
<p><span class="math">\[c_{a} = \frac{1}{N_s}\sum_i^{N_s}I(s_{ia} = sc_i)\]</span></p>
<p>where <span class="math">\(N_s\)</span> is the number of samples, <span class="math">\(s_{ia}\)</span> is the subgroup label of sample <span class="math">\(i\)</span> in partition <span class="math">\(a\)</span> and <span class="math">\(sc_i\)</span> is the consensus subgroup label for sample <span class="math">\(i\)</span>. Note class labels in single partitions have already been adjusted to the consensus partition labels.</p>
<p>The final concordance score is the mean value of <span class="math">\(c_a\)</span>. Higher the concordance score, better the <span class="math">\(k\)</span>.</p>
</div>
<div id="area-increased" class="section level3">
<h3 class="hasAnchor">
<a href="#area-increased" class="anchor"></a>Area increased</h3>
<p>It is the increased area under CDF of the consensus matrix compared to the previous <span class="math">\(k\)</span>.</p>
<p><span class="math">\[A_k = \int F_k(x) - \int F_{k-1}(x)\]</span></p>
<p>and when <span class="math">\(k = 2\)</span> or for the minimal <span class="math">\(k\)</span>:</p>
<p><span class="math">\[A_k = \int F_k(x)\]</span></p>
<p>In follow example, there are five consensus heatmaps corresponding to <span class="math">\(k =2,3,4,5,6\)</span>. Note the number of subgroups that can be inferred from the consensus heatmap is not necessary to be exactly the same as <span class="math">\(k\)</span>. It can be smaller than <span class="math">\(k\)</span>.</p>
<p><img src="cola_files/figure-html/unnamed-chunk-21-1.png" width="1344" style="display: block; margin: auto;"></p>
<p>The corresponding CDF curves and the area increased are:</p>
<p><img src="cola_files/figure-html/unnamed-chunk-22-1.png" width="960" style="display: block; margin: auto;"></p>
<p>The <span class="math">\(k\)</span> before the elbow is taken as the best <span class="math">\(k\)</span> (in above example it is 3). Basically when <span class="math">\(k\)</span> reaches a stable subgrouping, increasing <span class="math">\(k\)</span> won’t change the consensus matrix too much, which results in less change of the difference of area under the CDF curve.</p>
</div>
<div id="rand-index" class="section level3">
<h3 class="hasAnchor">
<a href="#rand-index" class="anchor"></a>Rand index</h3>
<p>In some cases, when number of subgroups changes from <span class="math">\(k-1\)</span> to <span class="math">\(k\)</span>, all the statistics imply <span class="math">\(k\)</span> is a better choice than <span class="math">\(k-1\)</span>. However, when observing the consensus heatmap, basically it is because a very small set of samples are separated to form a new subgroup. In this case, it is better to still keep <span class="math">\(k-1\)</span> subgroups. In other words, the subgrouping with <span class="math">\(k\)</span> is similar as <span class="math">\(k-1\)</span> and it is not worth to increase <span class="math">\(k\)</span> from <span class="math">\(k-1\)</span>. In <strong>cola</strong> package, there are two metrics: Rand index and Jaccard index to measure the similarity of two partitions for <span class="math">\(k-1\)</span> and <span class="math">\(k\)</span>. The two metrics are calculated by <code><a href="https://rdrr.io/pkg/clue/man/cl_agreement.html">clue::cl_agreement(..., method = "Rand")</a></code> and <code><a href="https://rdrr.io/pkg/clue/man/cl_agreement.html">clue::cl_agreement(..., method = "Jaccard")</a></code>.</p>
<p>For all pairs of samples, denote following symbols (<a href="https://en.wikipedia.org/wiki/Rand_index#Definition">https://en.wikipedia.org/wiki/Rand_index#Definition</a>):</p>
<ul>
<li>
<span class="math">\(a\)</span>: the number of pairs of samples that are in the same subgroup in <span class="math">\(k\)</span> and in the same subgroup in <span class="math">\(k-1\)</span>.</li>
<li>
<span class="math">\(b\)</span>: the number of pairs of samples that are in the different subgroup in <span class="math">\(k\)</span> and in the different subgroup in <span class="math">\(k-1\)</span>.</li>
<li>
<span class="math">\(c\)</span>: the number of pairs of samples that are in the same subgroup in <span class="math">\(k\)</span> and in the different subgroup in <span class="math">\(k-1\)</span>.</li>
<li>
<span class="math">\(d\)</span>: the number of pairs of samples that are in the different subgroup in <span class="math">\(k\)</span> and in the same subgroup in <span class="math">\(k-1\)</span>.</li>
</ul>
<p>the Rand index which is the percent of pairs of samples that are both in a same cluster or both are not in a same cluster in the partition of <span class="math">\(k\)</span> and <span class="math">\(k-1\)</span>.</p>
<p><span class="math">\[Rand = \frac{a+b}{a+b+c+d}\]</span></p>
<p>If Rand index is too high, it means the two subgroupings are very similar and it is not sufficient to increase from <span class="math">\(k-1\)</span> to <span class="math">\(k\)</span>.</p>
</div>
<div id="jaccard-index" class="section level3">
<h3 class="hasAnchor">
<a href="#jaccard-index" class="anchor"></a>Jaccard index</h3>
<p>The Jaccard index is the ratio of pairs of samples that are both in a same subgroup in the partition of <span class="math">\(k\)</span> and <span class="math">\(k-1\)</span> and the pairs of samples are both in a same subgroup in the partition of <span class="math">\(k\)</span> or <span class="math">\(k-1\)</span>.</p>
<p><span class="math">\[Jaccard = \frac{a}{a+c+d}\]</span></p>
<p>In following plots, when the number of subgroups increases from 3 to 4, there is only one single sample separated from other subgroups to form a new subgroup. The Rand index or the Jaccard index for <span class="math">\(k=4\)</span> is close to 1, which means, the subgroups at <span class="math">\(k=4\)</span> are highly similar as <span class="math">\(k=3\)</span>, thus we ignore <span class="math">\(k=4\)</span> and take <span class="math">\(k=3\)</span> as the better subgrouping.</p>
<p><img src="rand_jaccard.png" width="600"></p>
</div>
<div id="rule" class="section level3">
<h3 class="hasAnchor">
<a href="#rule" class="anchor"></a>Rule</h3>
<p><strong>cola</strong> provides a <code><a href="../reference/suggest_best_k-dispatch.html">suggest_best_k()</a></code> function which suggests the best <span class="math">\(k\)</span>. It is based on following rules:</p>
<ul>
<li>All <span class="math">\(k\)</span> with Rand index larger than 0.95 are removed because the increase of the partition number does not provides enough extra information. If all <span class="math">\(k\)</span> are removed, the best <span class="math">\(k\)</span> is assigned by <code>NA</code>.</li>
<li>For <span class="math">\(k\)</span> with 1-PAC larger than 0.9, the maximal <span class="math">\(k\)</span> is taken as the “best k”.</li>
<li>If it does not fit the second rule. The <span class="math">\(k\)</span> with the highest vote of highest 1-PAC, mean silhouette and concordance is taken as the “best k”.</li>
</ul>
<p><code><a href="../reference/suggest_best_k-dispatch.html">suggest_best_k()</a></code> only gives suggestion on selecting a reasonable <span class="math">\(k\)</span>. Users still need to look at the plots (e.g. by <code><a href="../reference/select_partition_number-ConsensusPartition-method.html">select_partition_number()</a></code> or <code><a href="../reference/consensus_heatmap-ConsensusPartition-method.html">consensus_heatmap()</a></code> functions), or even by checking whether the subgrouping gives a reasonable signatures by <code><a href="../reference/get_signatures-dispatch.html">get_signatures()</a></code>, to pick a reasonable <span class="math">\(k\)</span> that best explains their study.</p>
</div>
</div>
<div id="find-signatures" class="section level2">
<h2 class="hasAnchor">
<a href="#find-signatures" class="anchor"></a>Find signatures</h2>
<p>As long as there are stable subgroups, we can look for rows which show distinct difference in one subgroup compared to others. They can be called signature genes or signature CpG sites if the corresponding dataset is gene expression data or methylation data.</p>
<p>By default, samples with silhouette scores less than 0.5 are removed. <strong>cola</strong> provides following methods:</p>
<ul>
<li>
<code>Ftest</code> use F-test to find significantly different rows between subgroups.</li>
<li>
<code>ttest</code>: First it looks for the subgroup with highest mean value, compare to each of the other subgroups with t-test and take the maximum p-value. Second it looks for the subgroup with lowest mean value, compare to each of the other subgroups again with t-test and take the maximum p-values. Later for these two list of p-values take the minimal p-value as the final p-value.</li>
<li>
<code>samr</code> and <code>pamr</code>: use <a href="https://CRAN.R-project.org/package=samr">SAM</a>/<a href="https://CRAN.R-project.org/package=pamr">PAM</a> method to find significantly different rows between subgroups.</li>
<li>
<code>one_vs_others</code> For each subgroup <span class="math">\(i\)</span> in each row, it uses t-test to compare samples in current subgroup to all other samples, denoted as <span class="math">\(p_i\)</span>. The p-value for current row is selected as <span class="math">\(min(p_i)\)</span>.</li>
</ul>
<p>Users can also provide their own method by providing a function with the matrix and subgroup labels as inputs and a vector of FDR as output.</p>
</div>
<div id="gene-ontology-enrichment" class="section level2">
<h2 class="hasAnchor">
<a href="#gene-ontology-enrichment" class="anchor"></a>Gene ontology Enrichment</h2>
<p>If rows in the matrix can be associated to genes, <code><a href="../reference/GO_enrichment-dispatch.html">GO_enrichment()</a></code> can be applied to perform GO enrichment analysis to the signature genes.</p>
</div>
<div id="compare-multiple-methods" class="section level2">
<h2 class="hasAnchor">
<a href="#compare-multiple-methods" class="anchor"></a>Compare multiple methods</h2>
<p><code><a href="../reference/consensus_partition.html">consensus_partition()</a></code> is the core function for consensus partitioning. But it can only perform analysis with a single top-value method and a single partition method. In most cases, we have no idea of which combination of top-value method and partition method gives better results. Here <code><a href="../reference/run_all_consensus_partition_methods.html">run_all_consensus_partition_methods()</a></code> can perform analysis with multiple methods simultaneously:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># code is only for demonstration</span>
rl =<span class="st"> </span><span class="kw"><a href="../reference/run_all_consensus_partition_methods.html">run_all_consensus_partition_methods</a></span>(mat, 
    <span class="dt">top_value_method =</span> <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"sd"</span>, <span class="st">"MAD"</span>, ...),
    <span class="dt">partition_method =</span> <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="st">"hclust"</span>, <span class="st">"kmeans"</span>, ...),
    <span class="dt">mc.cores =</span> ...)</code></pre>
<p>By default it runs analysis for all combinations of top-value methods in <code><a href="../reference/all_top_value_methods.html">all_top_value_methods()</a></code> and partition methods in <code><a href="../reference/all_partition_methods.html">all_partition_methods()</a></code>.</p>
<p><strong>cola</strong> package provides functions to collect plots from all combinations of methods for straightforward comparisons.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># code is only for demonstration</span>
<span class="kw"><a href="../reference/collect_plots-dispatch.html">collect_plots</a></span>(rl, <span class="dt">fun =</span> consensus_heatmap, <span class="dt">k =</span> ...)
<span class="kw"><a href="../reference/collect_plots-dispatch.html">collect_plots</a></span>(rl, <span class="dt">fun =</span> membership_heatmap, <span class="dt">k =</span> ...)
<span class="kw"><a href="../reference/collect_plots-dispatch.html">collect_plots</a></span>(rl, <span class="dt">fun =</span> get_signatures, <span class="dt">k =</span> ...)</code></pre>
<p>And <code><a href="../reference/collect_classes-dispatch.html">collect_classes()</a></code> compares consensus partition from all methods:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># code is only for demonstration</span>
<span class="kw"><a href="../reference/collect_classes-dispatch.html">collect_classes</a></span>(rl, <span class="dt">k =</span> ...)</code></pre>
<p>The plots from <code><a href="../reference/collect_plots-dispatch.html">collect_plots()</a></code> and <code><a href="../reference/collect_classes-dispatch.html">collect_classes()</a></code> can be found <a href="#toc_27">here</a>.</p>
</div>
<div id="implementation-of-the-package" class="section level2">
<h2 class="hasAnchor">
<a href="#implementation-of-the-package" class="anchor"></a>Implementation of the package</h2>
<p><strong>cola</strong> is implemented in an object-oriented way. There are two main classes where <code>ConsensusPartition</code> class contains results for a single top-value method and a single partition method, while <code>ConsensusPartitionList</code> class contains results for multiple top-value methods and multiple partition methods.</p>
<p>In following example code, <code>TCGA_GBM_subgroup.rds</code> is generated by the code demonstrated <a href="https://jokergoo.github.io/cola_examples/">here</a> (Running cola analysis is always time-consuming, so we use the object that has already be generated.).</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://rdrr.io/r/utils/download.file.html">download.file</a></span>(<span class="st">"https://jokergoo.github.io/cola_examples/TCGA_GBM/TCGA_GBM_subgroup.rds"</span>, 
    <span class="dt">destfile =</span> <span class="st">"TCGA_GBM_subgroup.rds"</span>, <span class="dt">quiet =</span> <span class="ot">TRUE</span>)
rl =<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/readRDS.html">readRDS</a></span>(<span class="st">"TCGA_GBM_subgroup.rds"</span>)
<span class="kw"><a href="https://rdrr.io/r/base/files.html">file.remove</a></span>(<span class="st">"TCGA_GBM_subgroup.rds"</span>)</code></pre>
<p>Simply entering the variable name gives you the summary of the analysis and a list of functions that can be applied to this object:</p>
<pre class="sourceCode r"><code class="sourceCode r">rl</code></pre>
<pre><code>## A 'ConsensusPartitionList' object with 24 methods.
##   On a matrix with 11268 rows and 173 columns.
##   Top rows are extracted by 'sd, cv, MAD, ATC' methods.
##   Subgroups are detected by 'hclust, kmeans, skmeans, pam, mclust, NMF' method.
##   Number of partitions are tried for k = 2, 3, 4, 5, 6.
##   Performed in total 30000 partitions by row resampling.
## 
## Following methods can be applied to this 'ConsensusPartitionList' object:
##  [1] "cola_report"           "collect_classes"       "collect_plots"         "collect_stats"        
##  [5] "colnames"              "get_anno_col"          "get_anno"              "get_classes"          
##  [9] "get_matrix"            "get_membership"        "get_stats"             "GO_enrichment"        
## [13] "is_best_k"             "is_stable_k"           "ncol"                  "nrow"                 
## [17] "rownames"              "show"                  "suggest_best_k"        "test_to_known_factors"
## [21] "top_rows_heatmap"      "top_rows_overlap"     
## 
## You can get result for a single method by, e.g. object["sd", "hclust"] or object["sd:hclust"]
## or a subset of methods by object[c("sd", "cv")], c("hclust", "kmeans")]</code></pre>
<p>To get results for a single top-value method and partition method, you can subset <code>rl</code> by the name of the combination of the methods.</p>
<pre class="sourceCode r"><code class="sourceCode r">rl[<span class="st">"sd:hclust"</span>]</code></pre>
<pre><code>## A 'ConsensusPartition' object with k = 2, 3, 4, 5, 6.
##   On a matrix with 11268 rows and 173 columns.
##   Top rows (1000, 2000, 3000, 4000, 5000) are extracted by 'sd' method.
##   Subgroups are detected by 'hclust' method.
##   Performed in total 1250 partitions by row resampling.
##   Best k for subgroups seems to be 2.
## 
## Following methods can be applied to this 'ConsensusPartition' object:
##  [1] "cola_report"             "collect_classes"         "collect_plots"          
##  [4] "collect_stats"           "colnames"                "compare_signatures"     
##  [7] "consensus_heatmap"       "dimension_reduction"     "get_anno_col"           
## [10] "get_anno"                "get_classes"             "get_consensus"          
## [13] "get_matrix"              "get_membership"          "get_param"              
## [16] "get_signatures"          "get_stats"               "GO_enrichment"          
## [19] "is_best_k"               "is_stable_k"             "membership_heatmap"     
## [22] "ncol"                    "nrow"                    "plot_ecdf"              
## [25] "rownames"                "select_partition_number" "show"                   
## [28] "suggest_best_k"          "test_to_known_factors"</code></pre>
<p>Functions on <code>ConsensusPartitionList</code> class that are important to use are:</p>
<ul>
<li>
<code><a href="../reference/cola_report-dispatch.html">cola_report()</a></code>: Generate a HTML report for the complete analysis.</li>
<li>
<code><a href="../reference/collect_classes-dispatch.html">collect_classes()</a></code>: Plots consensus partition for every combination of methods. On top there is a global consensus partition summarized from all single-method-level partitions, weighted by the mean silhoutte scores.</li>
<li>
<code><a href="../reference/collect_plots-dispatch.html">collect_plots()</a></code>: Collect plots for all methods.</li>
<li>
<code><a href="../reference/get_classes-dispatch.html">get_classes()</a></code>: The global consensus subgroup by taking subgroups from all methods together.</li>
<li>
<code><a href="../reference/get_stats-dispatch.html">get_stats()</a></code>: Extract the statistics for determining best number of subgroups.</li>
<li>
<code><a href="../reference/suggest_best_k-dispatch.html">suggest_best_k()</a></code>: Guess the best <span class="math">\(k\)</span> for each method.</li>
<li>
<code><a href="../reference/test_to_known_factors-dispatch.html">test_to_known_factors()</a></code>: Apply tests to the annotations if provides. The test will be Chi-squared test or ANOVA depending on the data type of the annotation.</li>
<li>
<code><a href="../reference/top_rows_heatmap-dispatch.html">top_rows_heatmap()</a></code>: Make heatmaps for <code>top_n</code> rows under different top-value methods.</li>
<li>
<code><a href="../reference/top_rows_overlap-dispatch.html">top_rows_overlap()</a></code>: Make Venn-Euler diagram for the <code>top_n</code> rows under different top-value methods.</li>
<li>
<code><a href="../reference/GO_enrichment-dispatch.html">GO_enrichment()</a></code>: If rows can be associated to genes, it applies Gene ontology enrichment analysis.</li>
</ul>
<p>Functions on <code>ConsensusPartition</code> class:</p>
<ul>
<li>
<code><a href="../reference/collect_classes-dispatch.html">collect_classes()</a></code>: Make heatmaps for the consensus subgroups from all <span class="math">\(k\)</span>.</li>
<li>
<code><a href="../reference/collect_plots-dispatch.html">collect_plots()</a></code>: Collect all plots for consensus heatmaps, membership heatmaps and signature heatmaps for all <span class="math">\(k\)</span>.</li>
<li>
<code><a href="../reference/consensus_heatmap-ConsensusPartition-method.html">consensus_heatmap()</a></code>: Make consensus heatmap.</li>
<li>
<code><a href="../reference/dimension_reduction-dispatch.html">dimension_reduction()</a></code>: Make PCA plot.</li>
<li>
<code><a href="../reference/get_classes-dispatch.html">get_classes()</a></code>: Get class labels for a specific <span class="math">\(k\)</span>.</li>
<li>
<code><a href="../reference/get_consensus-ConsensusPartition-method.html">get_consensus()</a></code>: Get the consensus matrix for a specific <span class="math">\(k\)</span>.</li>
<li>
<code><a href="../reference/get_signatures-dispatch.html">get_signatures()</a></code>: Make the heatmap for the signatures.</li>
<li>
<code><a href="../reference/get_stats-dispatch.html">get_stats()</a></code>: Extract the statistics for determining best number of subgroups.</li>
<li>
<code><a href="../reference/suggest_best_k-dispatch.html">suggest_best_k()</a></code>: Guess the best <span class="math">\(k\)</span>.</li>
<li>
<code><a href="../reference/membership_heatmap-ConsensusPartition-method.html">membership_heatmap()</a></code>: Make the membership heatmap.</li>
<li>
<code><a href="../reference/plot_ecdf-ConsensusPartition-method.html">plot_ecdf()</a></code>: Plot the ECDF of the consensus matrix for all <span class="math">\(k\)</span>.</li>
<li>
<code><a href="../reference/select_partition_number-ConsensusPartition-method.html">select_partition_number()</a></code>: Make plots for all statistics for determining the best <span class="math">\(k\)</span>.</li>
<li>
<code><a href="../reference/test_to_known_factors-dispatch.html">test_to_known_factors()</a></code>: Apply tests to the annotations if provides. The test will be Fisher’s exact test or ANOVA depending on the data type of the annotation.</li>
<li>
<code><a href="../reference/GO_enrichment-dispatch.html">GO_enrichment()</a></code>: If rows can be associated to genes, it applies Gene ontology enrichment analysis.</li>
</ul>
</div>
<div id="visualizations" class="section level2">
<h2 class="hasAnchor">
<a href="#visualizations" class="anchor"></a>Visualizations</h2>
<p><strong>cola</strong> package provides rich visualizations for the results generated by a single method or multiple methods.</p>
<div id="on-the-consensuspartition-object" class="section level3">
<h3 class="hasAnchor">
<a href="#on-the-consensuspartition-object" class="anchor"></a>On the ConsensusPartition object</h3>
<p>The object which is generated with a single top-value method and a single partition method belongs to the class <code>ConsensusPartition</code>. There are several visualization functions that can be applied to it. <code><a href="../reference/select_partition_number-ConsensusPartition-method.html">select_partition_number()</a></code> makes several plots to show different statistics along with different <span class="math">\(k\)</span>, which helps to determine the “best k”.</p>
<pre class="sourceCode r"><code class="sourceCode r">res =<span class="st"> </span>rl[<span class="st">"MAD:kmeans"</span>] <span class="co"># the ConsensusPartition object</span>
<span class="kw"><a href="../reference/select_partition_number-ConsensusPartition-method.html">select_partition_number</a></span>(res)</code></pre>
<p><img src="cola_files/figure-html/unnamed-chunk-29-1.png" width="960" style="display: block; margin: auto;"></p>
<p>The heatmap for the consensus matrix with a certain <span class="math">\(k\)</span>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/consensus_heatmap-ConsensusPartition-method.html">consensus_heatmap</a></span>(res, <span class="dt">k =</span> <span class="dv">4</span>)</code></pre>
<p><img src="cola_files/figure-html/unnamed-chunk-30-1.png" width="700" style="display: block; margin: auto;"></p>
<p>The heatmap for the membership matrix with a certain <span class="math">\(k\)</span>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/membership_heatmap-ConsensusPartition-method.html">membership_heatmap</a></span>(res, <span class="dt">k =</span><span class="dv">4</span>)</code></pre>
<p><img src="cola_files/figure-html/unnamed-chunk-31-1.png" width="700" style="display: block; margin: auto;"></p>
<p>The PCA plot with a certain <span class="math">\(k\)</span>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/dimension_reduction-dispatch.html">dimension_reduction</a></span>(res, <span class="dt">k =</span> <span class="dv">4</span>)</code></pre>
<pre><code>## use UMAP</code></pre>
<p><img src="cola_files/figure-html/unnamed-chunk-32-1.png" width="700" style="display: block; margin: auto;"></p>
<p>The heatmap for the signature rows with a certain <span class="math">\(k\)</span>. The heatmap is split into two parts by columns. The left heatmap where the barplots on top are in black contains samples with silhouette scores larger than 0.5 and the right heatmap where the barplot son top are in grey contains samples with silhouette scores less than 0.5. Rows are automatically split by k-means.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/get_signatures-dispatch.html">get_signatures</a></span>(res, <span class="dt">k =</span> <span class="dv">4</span>)</code></pre>
<p><img src="cola_files/figure-html/unnamed-chunk-33-1.png" width="700" style="display: block; margin: auto;"></p>
<p><code><a href="../reference/collect_classes-dispatch.html">collect_classes()</a></code> which is applied on the <code>ConsensusPartition</code> object visualizes how subgroups are corresponded with increasing <span class="math">\(k\)</span>. Same row in all heatmaps corresponds to a same sample.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/collect_classes-dispatch.html">collect_classes</a></span>(res)</code></pre>
<p><img src="cola_files/figure-html/unnamed-chunk-34-1.png" width="700" style="display: block; margin: auto;"></p>
<p><code><a href="../reference/collect_plots-dispatch.html">collect_plots()</a></code> which is applied on the <code>ConsensusPartition</code> object puts all the plots from all <span class="math">\(k\)</span> into one single page.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/collect_plots-dispatch.html">collect_plots</a></span>(res)</code></pre>
<p><img src="cola_files/figure-html/unnamed-chunk-35-1.png" width="1344" style="display: block; margin: auto;"></p>
</div>
<div id="on-the-consensuspartitionlist-object" class="section level3">
<h3 class="hasAnchor">
<a href="#on-the-consensuspartitionlist-object" class="anchor"></a>On the ConsensusPartitionList object</h3>
<p><code><a href="../reference/run_all_consensus_partition_methods.html">run_all_consensus_partition_methods()</a></code> returns a <code>ConsensusPartitionList</code> object. There are two main functions which can visualize results from all combinations of methods and compare directly.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/collect_plots-dispatch.html">collect_plots</a></span>(rl, <span class="dt">fun =</span> consensus_heatmap, <span class="dt">k =</span> <span class="dv">4</span>)</code></pre>
<p><img src="cola_files/figure-html/unnamed-chunk-36-1.png" width="1344" style="display: block; margin: auto;"></p>
<p><code>fun</code> can also be <code>membership_heatmap</code> or <code>get_signatures</code> that membership heatmap and signature heatmap for each method will be plotted.</p>
<p><code><a href="../reference/collect_classes-dispatch.html">collect_classes()</a></code> which is applied on the <code>ConsensusPartitionList</code> object plots the partition for each combination of methods and the lightness correspond to the silhouette scores for samples in each method. Rows are clustered by the dissimilarity measurement from <code><a href="https://rdrr.io/pkg/clue/man/cl_dissimilarity.html">clue::cl_dissimilarity(..., method = "comembership")</a></code>. On top the consensus subgroup is inferred from all methods by taking the mean silhouette scores as weight.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/collect_classes-dispatch.html">collect_classes</a></span>(rl, <span class="dt">k =</span> <span class="dv">4</span>)</code></pre>
<p><img src="cola_files/figure-html/unnamed-chunk-37-1.png" width="960" style="display: block; margin: auto;"></p>
<p><code><a href="../reference/collect_stats-dispatch.html">collect_stats()</a></code> helps to compare statistics from multiple methods and multiple metrics.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/collect_stats-dispatch.html">collect_stats</a></span>(rl, <span class="dt">k =</span> <span class="dv">4</span>)</code></pre>
<p><img src="cola_files/figure-html/unnamed-chunk-38-1.png" width="960" style="display: block; margin: auto;"></p>
</div>
</div>
<div id="the-html-report" class="section level2">
<h2 class="hasAnchor">
<a href="#the-html-report" class="anchor"></a>The HTML report</h2>
<p>All the content introduced above is mainly for the deep understanding of the package. In real data analysis, users do not need to type that amount of code. <code><a href="../reference/cola_report-dispatch.html">cola_report()</a></code> function wraps all the code and performs the complete analysis automatically. Normally, applying <strong>cola</strong> analysis, following three lines of code are enough for you.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># code is only for demonstration</span>
mat =<span class="st"> </span><span class="kw"><a href="../reference/adjust_matrix.html">adjust_matrix</a></span>(mat) <span class="co"># for some datasets, you don't need this line.</span>
rl =<span class="st"> </span><span class="kw"><a href="../reference/run_all_consensus_partition_methods.html">run_all_consensus_partition_methods</a></span>(mat, <span class="dt">mc.cores =</span> ...)
<span class="kw"><a href="../reference/cola_report-dispatch.html">cola_report</a></span>(rl, <span class="dt">output_dir =</span> ...) <span class="co"># Alles ist da!</span></code></pre>
</div>
<div id="a-real-world-example" class="section level2">
<h2 class="hasAnchor">
<a href="#a-real-world-example" class="anchor"></a>A Real-world example</h2>
<p>In this example, we use <a href="https://www.ncbi.nlm.nih.gov/pubmed/20129251">the TCGA GBM microarray data set</a> where four subtypes is predicted. The two files (<code>unifiedScaled.txt</code> and <code>TCGA_unified_CORE_ClaNC840.txt</code>) for use is from <a href="https://tcga-data.nci.nih.gov/docs/publications/gbm_exp/">here</a>. The web page for the analysis is <a href="https://jokergoo.github.io/cola_examples/">https://jokergoo.github.io/cola_examples/</a>.</p>
<p>Following code is used to perform analysis of consensus partition.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># code is only for demonstration</span>
mat =<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/utils/read.table.html">read.table</a></span>(<span class="st">"https://jokergoo.github.io/cola_examples/unifiedScaled.txt"</span>, 
    <span class="dt">header =</span> <span class="ot">TRUE</span>, <span class="dt">row.names =</span> <span class="dv">1</span>, <span class="dt">check.names =</span> <span class="ot">FALSE</span>)
mat =<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span>(mat)

subtype =<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/utils/read.table.html">read.table</a></span>(<span class="st">"https://jokergoo.github.io/cola_examples/TCGA_unified_CORE_ClaNC840.txt"</span>, 
    <span class="dt">sep =</span> <span class="st">"</span><span class="ch">\t</span><span class="st">"</span>, <span class="dt">header =</span> <span class="ot">TRUE</span>, <span class="dt">check.names =</span> <span class="ot">FALSE</span>, <span class="dt">stringsAsFactors =</span> <span class="ot">FALSE</span>)
subtype =<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/structure.html">structure</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/unlist.html">unlist</a></span>(subtype[<span class="dv">1</span>, -(<span class="dv">1</span>:<span class="dv">2</span>)]), <span class="dt">names =</span> <span class="kw"><a href="../reference/colnames-dispatch.html">colnames</a></span>(subtype)[-(<span class="dv">1</span>:<span class="dv">2</span>)])

mat =<span class="st"> </span>mat[, <span class="kw"><a href="https://rdrr.io/r/base/names.html">names</a></span>(subtype)]

mat =<span class="st"> </span><span class="kw"><a href="../reference/adjust_matrix.html">adjust_matrix</a></span>(mat)
rl =<span class="st"> </span><span class="kw"><a href="../reference/run_all_consensus_partition_methods.html">run_all_consensus_partition_methods</a></span>(mat, <span class="dt">top_n =</span> <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">1000</span>, <span class="dv">2000</span>, <span class="dv">3000</span>, <span class="dv">4000</span>), 
    <span class="dt">max_k =</span> <span class="dv">6</span>, <span class="dt">mc.cores =</span> <span class="dv">4</span>, <span class="dt">anno =</span> <span class="kw"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span>(<span class="dt">subtype =</span> subtype), 
    <span class="dt">anno_col =</span> <span class="kw"><a href="https://rdrr.io/r/base/list.html">list</a></span>(<span class="dt">subtype =</span> <span class="kw"><a href="https://rdrr.io/r/base/structure.html">structure</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/seq.html">seq_len</a></span>(<span class="dv">4</span>), <span class="dt">names =</span> <span class="kw"><a href="https://rdrr.io/r/base/unique.html">unique</a></span>(subtype))))</code></pre>
<p>Simply typing <code>rl</code> gives a summary of the analysis:</p>
<pre class="sourceCode r"><code class="sourceCode r">rl</code></pre>
<pre><code>## A 'ConsensusPartitionList' object with 24 methods.
##   On a matrix with 11268 rows and 173 columns.
##   Top rows are extracted by 'sd, cv, MAD, ATC' methods.
##   Subgroups are detected by 'hclust, kmeans, skmeans, pam, mclust, NMF' method.
##   Number of partitions are tried for k = 2, 3, 4, 5, 6.
##   Performed in total 30000 partitions by row resampling.
## 
## Following methods can be applied to this 'ConsensusPartitionList' object:
##  [1] "cola_report"           "collect_classes"       "collect_plots"         "collect_stats"        
##  [5] "colnames"              "get_anno_col"          "get_anno"              "get_classes"          
##  [9] "get_matrix"            "get_membership"        "get_stats"             "GO_enrichment"        
## [13] "is_best_k"             "is_stable_k"           "ncol"                  "nrow"                 
## [17] "rownames"              "show"                  "suggest_best_k"        "test_to_known_factors"
## [21] "top_rows_heatmap"      "top_rows_overlap"     
## 
## You can get result for a single method by, e.g. object["sd", "hclust"] or object["sd:hclust"]
## or a subset of methods by object[c("sd", "cv")], c("hclust", "kmeans")]</code></pre>
<p>The HTML report for the analysis is available at <a href="https://jokergoo.github.io/cola_examples/TCGA_GBM/TCGA_GBM_subgroup_cola_report/cola_report.html">https://jokergoo.github.io/cola_examples/TCGA_GBM/TCGA_GBM_subgroup_cola_report/cola_report.html</a>.</p>
</div>
<div id="hierarchical-partitioning" class="section level2">
<h2 class="hasAnchor">
<a href="#hierarchical-partitioning" class="anchor"></a>Hierarchical partitioning</h2>
<p>Normal consensus partition methods aim to find <span class="math">\(k\)</span> subgroups at the same time. However, when 1. there are dominant subgroups, or 2. the number of potential subgroups are large, it is difficult to find secondary subgroups which show less difference with normal consensus partition process. To solve this problem, the subgroups can be found in a hierarchical way, where dominant subgroups are found first, and secondary subgroups are detected afterwards.</p>
<p><strong>cola</strong> package implements hierarchical partition and the flowchart is as follows.</p>
<p><img src="hierarchical_partition_workflow.png" width="460"></p>
<p>Generally, at each recursive step, the consensus partition is performed for a small set of <span class="math">\(k\)</span> (because the final larger number of subgroups will be detected hierarchically) and a subset of samples, If the PAC score of the “best k” is less than 0.2, the samples are split into two subgroups where the first group contains samples with largest distance to all other subgroups and the second groups are all other samples. For each of the two groups, if the number of samples is less than 6, the hierarchical partition stops, or it repeatedly performs the hierarchical partition on the subset of samples in the corresponding groups.</p>
<p>Hierarchical partition is performed by <code><a href="../reference/hierarchical_partition.html">hierarchical_partition()</a></code> function. Note you can only use one single top-value method and a single partition methods here.</p>
<p>In following example, we still use the TCGA GBM microarray datasets. The consensus partition which is summarized from all methods (from <code><a href="../reference/run_all_consensus_partition_methods.html">run_all_consensus_partition_methods()</a></code>) are added as an annotation to compare to the subgroups predicted by hierarchical partition.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># code is only for demonstration</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span>(RColorBrewer)
rh =<span class="st"> </span><span class="kw"><a href="../reference/hierarchical_partition.html">hierarchical_partition</a></span>(mat, <span class="dt">top_n =</span> <span class="kw"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="dv">1000</span>, <span class="dv">2000</span>, <span class="dv">3000</span>, <span class="dv">4000</span>),
    <span class="dt">top_value_method =</span> <span class="st">"MAD"</span>, <span class="dt">partition_method =</span> <span class="st">"kmeans"</span>,
    <span class="dt">anno =</span> <span class="kw"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span>(<span class="dt">subtype =</span> subtype,
        <span class="dt">consensus =</span> <span class="kw"><a href="../reference/get_classes-dispatch.html">get_classes</a></span>(rl, <span class="dt">k =</span> <span class="dv">4</span>)$class), 
    <span class="dt">anno_col =</span> <span class="kw"><a href="https://rdrr.io/r/base/list.html">list</a></span>(<span class="dt">subtype =</span> <span class="kw"><a href="https://rdrr.io/r/base/structure.html">structure</a></span>(<span class="kw"><a href="https://rdrr.io/r/base/seq.html">seq_len</a></span>(<span class="dv">4</span>), <span class="dt">names =</span> <span class="kw"><a href="https://rdrr.io/r/base/unique.html">unique</a></span>(subtype)),
        <span class="dt">consensus =</span> <span class="kw"><a href="https://rdrr.io/r/base/structure.html">structure</a></span>(<span class="kw"><a href="https://rdrr.io/pkg/RColorBrewer/man/ColorBrewer.html">brewer.pal</a></span>(<span class="dv">4</span>, <span class="st">"Set1"</span>), <span class="dt">names =</span> <span class="dv">1</span>:<span class="dv">4</span>)))</code></pre>
<p><code>rh</code> is already generated and can be downloaded from <a href="https://jokergoo.github.io/cola_examples/TCGA_GBM/TCGA_GBM_subgroup_hierarchical_partition.rds">here</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://rdrr.io/r/utils/download.file.html">download.file</a></span>(<span class="st">"https://jokergoo.github.io/cola_examples/TCGA_GBM/TCGA_GBM_subgroup_hierarchical_partition.rds"</span>, 
  <span class="dt">destfile =</span> <span class="st">"TCGA_GBM_subgroup_hierarchical_partition.rds"</span>, <span class="dt">quiet =</span> <span class="ot">TRUE</span>)
rh =<span class="st"> </span><span class="kw"><a href="https://rdrr.io/r/base/readRDS.html">readRDS</a></span>(<span class="st">"TCGA_GBM_subgroup_hierarchical_partition.rds"</span>)
<span class="kw"><a href="https://rdrr.io/r/base/files.html">file.remove</a></span>(<span class="st">"TCGA_GBM_subgroup_hierarchical_partition.rds"</span>)</code></pre>
<p>Simply typing <code>rh</code> gives the summary of the analysis.</p>
<pre class="sourceCode r"><code class="sourceCode r">rh</code></pre>
<pre><code>## A 'HierarchicalPartition' object with 'ATC:skmeans' method.
##   On a matrix with 11268 rows and 173 columns.
##   Performed in total 21750 partitions by row resampling.
##   There are 15 groups.
## 
## Hierarchy of the partition:
##   0, 173 cols
##   |-- 02, 53 cols
##   |   |-- 021, 16 cols
##   |   `-- 020, 37 cols
##   |       |-- 0201, 21 cols
##   |       |   |-- 02011, 9 cols
##   |       |   `-- 02010, 12 cols
##   |       `-- 0200, 16 cols
##   `-- 00, 120 cols
##       |-- 001, 43 cols
##       |   |-- 0012, 11 cols
##       |   `-- 0010, 32 cols
##       |       |-- 00103, 9 cols
##       |       `-- 00100, 23 cols
##       |           |-- 001001, 8 cols
##       |           `-- 001000, 15 cols
##       `-- 000, 77 cols
##           |-- 0001, 37 cols
##           |   |-- 00011, 21 cols
##           |   |   |-- 000111, 10 cols
##           |   |   `-- 000110, 11 cols
##           |   `-- 00010, 16 cols
##           |       |-- 000101, 7 cols
##           |       `-- 000100, 9 cols
##           `-- 0000, 40 cols
##               |-- 00001, 22 cols
##               `-- 00000, 18 cols
##                   |-- 000001, 7 cols
##                   `-- 000000, 11 cols
## 
## Following methods can be applied to this 'HierarchicalPartition' object:
##  [1] "all_leaves"            "all_nodes"             "cola_report"           "collect_classes"      
##  [5] "collect_plots"         "colnames"              "dimension_reduction"   "get_anno_col"         
##  [9] "get_anno"              "get_classes"           "get_matrix"            "get_signatures"       
## [13] "GO_enrichment"         "max_depth"             "ncol"                  "nrow"                 
## [17] "rownames"              "show"                  "suggest_best_k"        "test_to_known_factors"
## 
## You can get result for a single node by e.g. object["01"]</code></pre>
<p><strong>cola</strong> uses a special way to encode the node in the hierarchy. The length of the node name is the depth of the node in the hierarchy and the substring excluding the last digit is the node name of the parent node. E.g. for the node <code>0011</code>, the depth is 4 and the parent node is <code>001</code>. For each node, the last digit represents the index of the subgroup detected in parent node. and 0 represents all other subgroups. E.g. <code>02</code> means this node contains samples which belong to subgroup 2 when doing consensus partition at node 0 (subgroup 2 is selected as a node because the intra-group distance is smallest compared to other subgroups), and <code>00</code> contains samples which do not belong to subgroup 2 at node 0.</p>
<p>On each node of the partition hierarchy, it is a <code>ConsensusPartition</code> object (note it is not a sub-hierarchy) and it can be retrieved by using node name as index.</p>
<pre class="sourceCode r"><code class="sourceCode r">rh[<span class="st">"00"</span>]</code></pre>
<pre><code>## A 'ConsensusPartition' object with k = 2, 3, 4.
##   On a matrix with 11268 rows and 120 columns.
##   Top rows (1000, 2000, 3000, 4000, 5000) are extracted by 'ATC' method.
##   Subgroups are detected by 'skmeans' method.
##   Performed in total 750 partitions by row resampling.
##   Best k for subgroups seems to be 3.
## 
## Following methods can be applied to this 'ConsensusPartition' object:
##  [1] "cola_report"             "collect_classes"         "collect_plots"          
##  [4] "collect_stats"           "colnames"                "compare_signatures"     
##  [7] "consensus_heatmap"       "dimension_reduction"     "get_anno_col"           
## [10] "get_anno"                "get_classes"             "get_consensus"          
## [13] "get_matrix"              "get_membership"          "get_param"              
## [16] "get_signatures"          "get_stats"               "GO_enrichment"          
## [19] "is_best_k"               "is_stable_k"             "membership_heatmap"     
## [22] "ncol"                    "nrow"                    "plot_ecdf"              
## [25] "rownames"                "select_partition_number" "show"                   
## [28] "suggest_best_k"          "test_to_known_factors"</code></pre>
<p><code><a href="../reference/collect_classes-dispatch.html">collect_classes()</a></code> plots the hierarchy of subgroups as well as the annotations that are set before.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/collect_classes-dispatch.html">collect_classes</a></span>(rh)</code></pre>
<p><img src="cola_files/figure-html/unnamed-chunk-46-1.png" width="700" style="display: block; margin: auto;"></p>
<p>In above plot, generally hierarchical partition found similar subgroups as consensus partition, but hierarchical partition additionally found two subgroups for the Mesenchymal subtype samples, which makes totally 5 subgroups. However, if we directly check the 5 subgroups in <code>rl</code>, actually the subgrouping is not stable (see following consensus heatmap). This means the difference between the two subgroups in Mesenchymal is so small that it cannot be distinguished if we take all samples in the analysis.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/consensus_heatmap-ConsensusPartition-method.html">consensus_heatmap</a></span>(rl[<span class="st">"MAD:kmeans"</span>], <span class="dt">k =</span> <span class="dv">5</span>)</code></pre>
<p><img src="cola_files/figure-html/unnamed-chunk-47-1.png" width="700" style="display: block; margin: auto;"></p>
<p>In the hierarchical partition, the two subgroups of Mesenchymal subtype are under the node <code>001</code>. If only applying consensus partition on node <code>001</code>, actually there are two obvious subgroups and there are quite a lot signature genes which are significantly different between the two subgroups. This proves it is very meanningful that there are two secondary subgroups in Mesenchymal subtype.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/get_signatures-dispatch.html">get_signatures</a></span>(rh[<span class="st">"001"</span>], <span class="dt">k =</span> <span class="dv">2</span>)</code></pre>
<p><img src="cola_files/figure-html/unnamed-chunk-48-1.png" width="700" style="display: block; margin: auto;"></p>
<p><code>get_sigatures()</code> can also be applied to the <code>rh</code> object to visualize the signature rows found in every node in the partition hierarchy.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/get_signatures-dispatch.html">get_signatures</a></span>(rh, <span class="dt">verbose =</span> <span class="ot">FALSE</span>)</code></pre>
<p><img src="cola_files/figure-html/unnamed-chunk-49-1.png" width="700" style="display: block; margin: auto;"></p>
<p>Similar as the <code>ConsensusPartitionList</code> object, <code><a href="../reference/cola_report-dispatch.html">cola_report()</a></code> function can also be applied to this <code>HierarchicalPartition</code> object. The full report for <code>rh</code> can be found at <a href="https://jokergoo.github.io/cola_examples/TCGA_GBM/TCGA_GBM_subgroup_hierarchical_partition_cola_report/cola_hc.html">https://jokergoo.github.io/cola_examples/TCGA_GBM/TCGA_GBM_subgroup_hierarchical_partition_cola_report/cola_hc.html</a>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># code is only for demonstration</span>
<span class="kw"><a href="../reference/cola_report-dispatch.html">cola_report</a></span>(rh, <span class="dt">output_dir =</span> <span class="st">"~/your-output-folder/tcga_cola_rh_report"</span>)</code></pre>
<p>Following functions can be applied to the <code>HierarchicalPartition</code> class:</p>
<ul>
<li>
<code><a href="../reference/cola_report-dispatch.html">cola_report()</a></code>: Generate a HTML report for the complete analysis.</li>
<li>
<code><a href="../reference/collect_classes-dispatch.html">collect_classes()</a></code>: Make heatmaps for the hierarchical partition.</li>
<li>
<code><a href="../reference/dimension_reduction-dispatch.html">dimension_reduction()</a></code>: Make PCA plot.</li>
<li>
<code><a href="../reference/get_classes-dispatch.html">get_classes()</a></code>: Get class labels at a specific depth of the hierarchy.</li>
<li>
<code><a href="../reference/get_signatures-dispatch.html">get_signatures()</a></code>: Make the heatmap for the signatures.</li>
<li>
<code><a href="../reference/test_to_known_factors-dispatch.html">test_to_known_factors()</a></code>: Apply tests to the annotations if provides. The test will be Fisher’s exact test or ANOVA depending on the data type of the annotation.</li>
</ul>
</div>
<div id="session-info" class="section level2">
<h2 class="hasAnchor">
<a href="#session-info" class="anchor"></a>Session info</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="https://rdrr.io/r/utils/sessionInfo.html">sessionInfo</a></span>()</code></pre>
<pre><code>## R version 3.6.0 (2019-04-26)
## Platform: x86_64-pc-linux-gnu (64-bit)
## Running under: CentOS Linux 7 (Core)
## 
## Matrix products: default
## BLAS:   /usr/lib64/libblas.so.3.4.2
## LAPACK: /usr/lib64/liblapack.so.3.4.2
## 
## locale:
##  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8       
##  [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
##  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                  LC_ADDRESS=C              
## [10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       
## 
## attached base packages:
## [1] grid      stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] GetoptLong_0.1.7     mvtnorm_1.0-11       matrixStats_0.55.0   cola_1.1.2          
## [5] circlize_0.4.9       ComplexHeatmap_2.0.0 knitr_1.25           markdown_1.1        
## 
## loaded via a namespace (and not attached):
##  [1] bitops_1.0-6         fs_1.3.1             bit64_0.9-7          RColorBrewer_1.1-2  
##  [5] httr_1.4.1           rprojroot_1.3-2      data.tree_0.7.8      tools_3.6.0         
##  [9] backports_1.1.5      R6_2.4.0             lazyeval_0.2.2       DBI_1.0.0           
## [13] BiocGenerics_0.30.0  colorspace_1.4-1     gridExtra_2.3        tidyselect_0.2.5    
## [17] bit_1.1-14           compiler_3.6.0       Biobase_2.44.0       xml2_1.2.2          
## [21] influenceR_0.1.0     microbenchmark_1.4-7 desc_1.2.0           slam_0.1-45         
## [25] scales_1.0.0         readr_1.3.1          genefilter_1.66.0    askpass_1.1         
## [29] pkgdown_1.4.1        stringr_1.4.0        digest_0.6.21        rmarkdown_1.15      
## [33] pkgconfig_2.0.3      htmltools_0.3.6      umap_0.2.3.1         htmlwidgets_1.3     
## [37] rlang_0.4.0          GlobalOptions_0.1.1  rstudioapi_0.10      RSQLite_2.1.2       
## [41] impute_1.58.0        visNetwork_2.0.8     shape_1.4.4          jsonlite_1.6        
## [45] mclust_5.4.5         dendextend_1.12.0    dplyr_0.8.3          rgexf_0.15.3        
## [49] RCurl_1.95-4.12      magrittr_1.5         Matrix_1.2-17        munsell_0.5.0       
## [53] Rcpp_1.0.2           S4Vectors_0.22.1     viridis_0.5.1        reticulate_1.13     
## [57] lifecycle_0.1.0      stringi_1.4.3        MASS_7.3-51.4        blob_1.2.0          
## [61] parallel_3.6.0       crayon_1.3.4         lattice_0.20-38      splines_3.6.0       
## [65] annotate_1.62.0      hms_0.5.1            zeallot_0.1.0        pillar_1.4.2        
## [69] igraph_1.2.4.1       rjson_0.2.20         stats4_3.6.0         XML_3.98-1.20       
## [73] glue_1.3.1           evaluate_0.14        downloader_0.4       png_0.1-7           
## [77] vctrs_0.2.0          gtable_0.3.0         tidyr_1.0.0          openssl_1.4.1       
## [81] purrr_0.3.3          clue_0.3-57          assertthat_0.2.1     ggplot2_3.2.1       
## [85] xfun_0.9             eulerr_5.1.0         xtable_1.8-4         skmeans_0.2-11      
## [89] RSpectra_0.15-0      viridisLite_0.3.0    survival_2.44-1.1    tibble_2.1.3        
## [93] AnnotationDbi_1.46.1 memoise_1.1.0        IRanges_2.18.3       Rook_1.1-1          
## [97] cluster_2.1.0        DiagrammeR_1.0.1     brew_1.0-6</code></pre>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">

        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li>
<a href="#cola-a-general-framework-for-consensus-and-hierarchical-partitioning">cola: A General Framework for Consensus and Hierarchical Partitioning</a><ul class="nav nav-pills nav-stacked">
<li><a href="#introduction">Introduction</a></li>
      <li><a href="#the-input-matrix">The input matrix</a></li>
      <li><a href="#basic-usage">Basic usage</a></li>
      <li><a href="#top-value-methods">Top-value methods</a></li>
      <li><a href="#partition-methods">Partition methods</a></li>
      <li><a href="#consensus-partitioning">Consensus partitioning</a></li>
      <li><a href="#determine-the-best-number-of-subgroups">Determine the best number of subgroups</a></li>
      <li><a href="#find-signatures">Find signatures</a></li>
      <li><a href="#gene-ontology-enrichment">Gene ontology Enrichment</a></li>
      <li><a href="#compare-multiple-methods">Compare multiple methods</a></li>
      <li><a href="#implementation-of-the-package">Implementation of the package</a></li>
      <li><a href="#visualizations">Visualizations</a></li>
      <li><a href="#the-html-report">The HTML report</a></li>
      <li><a href="#a-real-world-example">A Real-world example</a></li>
      <li><a href="#hierarchical-partitioning">Hierarchical partitioning</a></li>
      <li><a href="#session-info">Session info</a></li>
      </ul>
</li>
      </ul>
</div>
      </div>

</div>



      <footer><div class="copyright">
  <p>Developed by Zuguang Gu.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.4.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
